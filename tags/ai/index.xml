<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Maxime NEMO - Portfolio</title>
    <link>https://maximene.github.io/AboutMe.github.io/tags/ai/</link>
    <description>Recent content in AI on Maxime NEMO - Portfolio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Nov 2021 21:02:41 +0200</lastBuildDate><atom:link href="https://maximene.github.io/AboutMe.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ens&#39;IA association</title>
      <link>https://maximene.github.io/AboutMe.github.io/posts/ensia/</link>
      <pubDate>Sun, 28 Nov 2021 21:02:41 +0200</pubDate>
      
      <guid>https://maximene.github.io/AboutMe.github.io/posts/ensia/</guid>
      <description>What is Ens&amp;rsquo;IA Ens&amp;rsquo;IA is a french AI association aiming to :
 Promote AI and its applications Organize with partners, companies or other student associations, events and activities such as conferences, training workshops, collaborative workshops, professional-student meetings, etc. Organize AI competitions and challenges in France Promoting ethical and responsible AI  You can find the free courses we offer on our github page
My work at Ens&amp;rsquo;IA  I am taking part in the sessions Ens&amp;rsquo;IA offers : I am one of the two person giving the lecture.</description>
    </item>
    
    <item>
      <title>Virtual Drag and Drop using hand</title>
      <link>https://maximene.github.io/AboutMe.github.io/posts/virtualdraganddrop/</link>
      <pubDate>Wed, 03 Nov 2021 17:40:42 +0100</pubDate>
      
      <guid>https://maximene.github.io/AboutMe.github.io/posts/virtualdraganddrop/</guid>
      <description>VirtualDragAndDrop This programs create a virtual drag and drop on objects represented by their centers. I used rectangle for this example.
To use the program, just run the file main.py. Then to move an object, you have to &amp;ldquo;grab it&amp;rdquo; = close your hand when your hand is on the object. Then opening your hand will release the object.
I used Python with OpenCV and cvzone to detect the hand. A next step would be to recreate the hand detection by myself.</description>
    </item>
    
    <item>
      <title>Challenge DATA &amp; AI by Ens&#39;IA and Neovision</title>
      <link>https://maximene.github.io/AboutMe.github.io/posts/challenge_data_ia/</link>
      <pubDate>Fri, 06 Aug 2021 11:05:23 +0200</pubDate>
      
      <guid>https://maximene.github.io/AboutMe.github.io/posts/challenge_data_ia/</guid>
      <description>The challenge: This challenge is about the well known subject of Optical Character Recognition (OCR).
The goal is quite simple : building the best model to recognize the characters in the dataset given by Neovision. (private dataset)
The results: My team managed to end in second position with a macro-averaged accuracy of 0.78.
The model: My model is available in my github (french version). https://github.com/MaximeNe/Challenge-DATA-IA
We tried different methods. We worked on transfer learning, on image preprocessing, on segmentation, etc&amp;hellip; The best result used transfer learning with ImageNet</description>
    </item>
    
  </channel>
</rss>
